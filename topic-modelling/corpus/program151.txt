<DOC>
first principles of computer vision
this presents the first comprehensive treatment of the foundations of computer vision it focuses on the mathematical and physical underpinnings of vision and has been designed for learners practitioners and researchers who have little or no knowledge of computer vision the includes a series of courses any learner who completes this has the potential to build a successful in computer vision a thriving field that is expected to increase in importance in the coming decades




learners will develop the fundamental knowledge of computer vision by applying the models and tools including image processing image features constructing d scene image segmentation and object recognition the includes roughly assessment questions proficiency in the fundamentals of computer vision is valued by a wide range of technology companies and research organizations



</DOC>

<DOC>
d reconstruction single viewpoint
this focuses on the recovery of the d structure of a scene from its d images in particular we are interested in the d reconstruction of a rigid scene from images taken by a stationary camera same viewpoint this problem is interesting as we want the multiple images of the scene to capture complementary information despite the fact that the scene is rigid and the camera is fixed to this end we explore several ways of capturing images where each image provides additional information about the scene
in order to estimate scene properties depth surface orientation material properties etc we first define several important radiometric concepts such as light source intensity surface illumination surface brightness image brightness and surface reflectance then we tackle the challenging problem of shape from shading recovering the shape of a surface from its shading in a single image next we show that if multiple images of a scene of known reflectance are taken while changing the illumination direction the surface normal at each scene point can be computed this method called photometric stereo provides a dense surface normal map that can be integrated to obtain surface shape next we discuss depth from defocus which uses the limited depth of field of the camera to estimate scene structure from a small number of images taken by changing the focus setting of the lens a dense depth of the scene is recovered finally we present a suite of techniques that use active illumination the projection of light patterns onto the scene to get precise d reconstructions of the scene these active illumination methods are the workhorse of factory automation they are used on manufacturing lines to assemble products and inspect their visual quality they are also extensively used in other domains such as driverless cars robotics surveillance medical imaging and special effects in movies

getting started d reconstruction single viewpoint
discussion prompts plugins

radiometry and reflectance
reading discussion prompts plugins

photometric stereo
reading discussion prompts plugins

shape from shading
discussion prompts plugins

depth from defocus
discussion prompts plugins

active illumination methods
reading discussion prompts plugins
</DOC>

<DOC>
features and boundaries
this focuses on the detection of features and boundaries in images feature and boundary detection is a critical preprocessing step for a variety of vision tasks including object detection object recognition and metrology the measurement of the physical dimensions and other properties of objects the presents a variety of methods for detecting features and boundaries and shows how features extracted from an image can be used to solve important vision tasks
we begin with the detection of simple but important features such as edges and corners we show that such features can be reliably detected using operators that are based on the first and second derivatives of images next we explore the concept of an interest point a unique and hence useful local appearance in an image we describe how interest points can be robustly detected using the sift detector using this detector we describe an endtoend solution to the problem of stitching overlapping images of a scene to obtain a wideangle panorama finally we describe the important problem of finding faces in images and show several applications of face detection

getting started features and boundaries
discussion prompts plugins

edge detection
discussion prompts plugins

boundary detection
discussion prompts plugins

sift detector
reading discussion prompts plugins

image stitching
reading discussion prompt plugins

face detection
discussion prompts plugins
</DOC>

<DOC>
camera and imaging
this covers the fundamentals of imaging the creation of an image that is ready for consumption or processing by a human or a machine imaging has a long history spanning several centuries but the advances made in the last three decades have revolutionized the camera and dramatically improved the robustness and accuracy of computer vision systems we describe the fundamentals of imaging as as recent innovations in imaging that have had a profound impact on computer vision
this starts with examining how an image is formed using a lens camera we explore the optical characteristics of a camera such as its magnification fnumber depth of field and field of view next we describe how solidstate image sensors ccd and cmos record images and the key properties of an image sensor such as its resolution noise characteristics and dynamic range we describe how image sensors can be used to sense color as as capture images with high dynamic range in certain structured environments an image can be thresholded to produce a binary image from which various geometric properties of objects can be computed and used for recognizing and locating objects finally we present the fundamentals of image processing the development of computational tools to process a captured image to make it cleaner denoising deblurring etc and easier for computer vision systems to analyze linear and nonlinear image filtering methods

getting started camera and imaging
discussion prompts plugins

image formation
discussion prompts plugins

image sensing
discussion prompts plugins

binary images
discussion prompts plugins

image processing i
discussion prompts plugins

image processing ii
discussion prompt plugins
</DOC>

<DOC>
visual perception
the ultimate goal of a computer vision system is to generate a detailed symbolic of each image shown this focuses on the allimportant problem of perception
we first describe the problem of tracking objects in complex scenes we look at two key challenges context the first is the separation of an image into object and background using a technique called change detection the second is the tracking of one or more objects in a next we examine the problem of segmenting an image into meaningful regions in particular we take a bottomup approach where pixels with similar attributes are grouped together to obtain a region finally we tackle the problem of object recognition we describe two approaches to the problem the first directly recognize an object and its pose using the appearance of the object this method is based on the concept of dimension reduction which is achieved using principal component analysis the second approach is to use a neural network to solve the recognition problem as one of learning a mapping from the input image to the output object class object identity activity etc we describe how a neural network is constructed and how it is trained using the backpropagation algorithm

getting started visual perception
plugins

object tracking
reading discussion prompt plugins

image segmentation
plugins

appearance matching
discussion prompt plugins

neural networks
reading peer review discussion prompt plugins
</DOC>

<DOC>
d reconstruction multiple viewpoints
this focuses on the recovery of the d structure of a scene from images taken from different viewpoints we start by first building a comprehensive geometric model of a camera and then develop a method for finding calibrating the internal and external parameters of the camera model then we show how two such calibrated cameras whose relative positions and orientations are known can be used to recover the d structure of the scene this is what we refer to as simple binocular stereo next we tackle the problem of uncalibrated stereo where the relative positions and orientations of the two cameras are unknown interestingly just from the two images taken by the cameras we can both determine the relative positions and orientations of the cameras and then use this information to estimate the d structure of the scene
next we focus on the problem of dynamic scenes given two images of a scene that includes moving objects we show how the motion of each point in the image can be computed this apparent motion of points in the image is called optical flow optical flow estimation allows us to track scene points over a sequence next we consider the of a scene shot using a moving camera where the motion of the camera is unknown we present structure from motion that takes as input tracked features in such a and determines not only the d structure of the scene but also how the camera moves with respect to the scene the methods we develop in the are widely used in object modeling d site modeling robotics autonomous navigation virtual reality and augmented reality

getting started d reconstruction multiple viewpoints
discussion prompts plugins

camera calibration
reading discussion prompts plugins

uncalibrated stereo
discussion prompts plugins

optical flow
reading discussion prompt plugins

structure from motion
discussion prompts plugins
</DOC>

